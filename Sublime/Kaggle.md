Kaggle简介：
Kaggle创立于2010，是一个专注于举办数据科学周边的线上竞赛的网站。它吸引了大量数据科学家、机器学习开发者的参与，为各类现实中的商业难题开发基于数据的算法解决方案。竞赛的获胜者、领先者，在收获对方公司提供的优厚报酬之外，还将引起业内科技巨头的注意，获得各路 HR 青睐，为自己的职业道路铺上红地毯。
Kaggle 是当今最大的数据科学家、机器学习开发者社区，其行业地位独一无二。

Kaggle是由联合创始人、首席执行官安东尼·高德布卢姆（Anthony Goldbloom）2010年在墨尔本创立的，主要为开发商和数据科学家提供举办机器学习竞赛、托管数据库、编写和分享代码的平台。该平台已经吸引了80万名数据科学家的关注，这些用户资源或许正是吸引谷歌的主要因素。

# 20170824 
# 实战1：Titanic: Machine Learning from Disaster

##Practice Skills
- Binary classification
- Python and R basics

##Goal
It is your job to predict if a passenger survived the sinking of the Titanic or not. 
For each PassengerId in the test set, you must predict a 0 or 1 value for the Survived variable.

## 思路
- 有监督的学习
三个文件：提交举例文件、训练集、测试集（需要结果提交上去）
训练集分成两个部分：训练集和测试集
1. 文件的读取和保存
2. 文件中缺失值处理
3. 二分法分类
4. 数据预处理

12个属性，题目中没有说编号passenger和名字name
名字中间用逗号隔开了
数值化数据
训练集和数据集不一样，需要不同的处理方式

选取的特征：pclass、sex、age、sibsp、parch、fare、cabin、
算法：决策树、knn、贝叶斯
0.755

优化方案：选取贝叶斯。
- 去掉cabin 0.751
- 考虑ticket，8个特征+名+号+仓

- 缺失值处理方式：mean
- 五种分类方法：神经网络、svm
svm中的linear参数再次创新高0.765
新思路：多次训练数据集，取最高的一次。
决策树和svm有不确定性
knn和贝叶斯多次训练结果不变

linear准确率最高，达到0.77033了

决策树：0.843575418994
有监督学习：分类和回归

np.idnan
loc,iloc

感觉在数据挖掘竞赛中，如果大家都用同样的算法库，影响最终结果的，就是三个因素（因为没法获得更多的数据）：1、数据的预处理方式 2、特征工程 3、算法的参数调整。 数据的处理包括丢失数据的处理，数据类型的转换。特征工程则是最复杂的部分，有人可以利用已有的特征挖掘出更多的特征，有的特征是多余的，这个过程中有很多方法。参数调整可以利用gridsearch这样的工具，但还是乏味无聊的。毕竟第一次做比赛，经验还太少，有些体会可能也是不对的，如果有错，期待大家的批评指正。也期待有朋友可以交流这个比赛！一个完成基本任务的代码如下。





